{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "603c870f",
      "metadata": {},
      "source": [
        "# Floating Array Design Project, Deep Case, Humboldt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7faae12c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from time import perf_counter\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from waves import Project\n",
        "from waves.utilities import load_yaml\n",
        "\n",
        "# Update core Pandas display settings\n",
        "pd.options.display.float_format = \"{:,.2f}\".format\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0986321e",
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_configuration = {\n",
        "    \"# Turbines\": {\"metric\": \"n_turbines\"},\n",
        "    \"Turbine Rating (MW)\": {\"metric\": \"turbine_rating\"},\n",
        "    \"Project Capacity (MW)\": {\n",
        "        \"metric\": \"capacity\",\n",
        "        \"kwargs\": {\"units\": \"mw\"}\n",
        "    },\n",
        "    \"# OSS\": {\"metric\": \"n_substations\"},\n",
        "    \"Total Export Cable Length (km)\": {\"metric\": \"export_system_total_cable_length\"},\n",
        "    \"Total Array Cable Length (km)\": {\"metric\": \"array_system_total_cable_length\"},\n",
        "    \"CapEx ($)\": {\"metric\": \"capex\"},\n",
        "    \"CapEx per kW ($/kW)\": {\n",
        "        \"metric\": \"capex\",\n",
        "        \"kwargs\": {\"per_capacity\": \"kw\"}\n",
        "    },\n",
        "    \"OpEx ($)\": {\"metric\": \"opex\"},\n",
        "    \"OpEx per kW ($/kW)\": {\"metric\": \"opex\", \"kwargs\": {\"per_capacity\": \"kw\"}},\n",
        "    \"AEP (MWh)\": {\n",
        "        \"metric\": \"energy_production\",\n",
        "        \"kwargs\": {\"units\": \"mw\", \"aep\": True}\n",
        "    },\n",
        "    \"AEP per kW (MWh/kW)\": {\n",
        "        \"metric\": \"energy_production\",\n",
        "        \"kwargs\": {\"units\": \"mw\", \"per_capacity\": \"kw\", \"aep\": True}\n",
        "    },\n",
        "    \"Net Capacity Factor With All Losses (%)\": {\n",
        "        \"metric\": \"capacity_factor\",\n",
        "        \"kwargs\": {\"which\": \"net\"}\n",
        "    },\n",
        "    \"Gross Capacity Factor (%)\": {\n",
        "        \"metric\": \"capacity_factor\",\n",
        "        \"kwargs\": {\"which\": \"gross\"}\n",
        "    },\n",
        "    \"Energy Availability (%)\": {\n",
        "        \"metric\": \"availability\",\n",
        "        \"kwargs\": {\"which\": \"energy\"}\n",
        "    },\n",
        "    \"LCOE ($/MWh)\": {\"metric\": \"lcoe\"},\n",
        "}\n",
        "\n",
        "\n",
        "# Define the final order of the metrics in the resulting dataframes\n",
        "metrics_order = [\n",
        "    \"# Turbines\",\n",
        "    \"Turbine Rating (MW)\",\n",
        "    \"Project Capacity (MW)\",\n",
        "    \"# OSS\",\n",
        "    \"Total Export Cable Length (km)\",\n",
        "    \"Total Array Cable Length (km)\",\n",
        "    \"FCR (%)\",\n",
        "    \"Offtake Price ($/MWh)\",\n",
        "    \"CapEx ($)\",\n",
        "    \"CapEx per kW ($/kW)\",\n",
        "    \"OpEx ($)\",\n",
        "    \"OpEx per kW ($/kW)\",\n",
        "    \"Annual OpEx per kW ($/kW)\",\n",
        "    \"Energy Availability (%)\",\n",
        "    \"Gross Capacity Factor (%)\",\n",
        "    \"Net Capacity Factor With All Losses (%)\",\n",
        "    \"AEP (MWh)\",\n",
        "    \"AEP per kW (MWh/kW)\",\n",
        "    \"LCOE ($/MWh)\",\n",
        "    \"Potential AEP from WOMBAT (kWh)\",\n",
        "    \"Production AEP from WOMBAT (kWh)\",\n",
        "]\n",
        "\n",
        "capex_order = [\n",
        "    \"Array System\",\n",
        "    \"Export System\",\n",
        "    \"Offshore Substation\",\n",
        "    \"Substructure\",\n",
        "    \"Scour Protection\",\n",
        "    \"Mooring System\",\n",
        "    \"Turbine\",\n",
        "    \"Array System Installation\",\n",
        "    \"Export System Installation\",\n",
        "    \"Offshore Substation Installation\",\n",
        "    \"Substructure Installation\",\n",
        "    \"Scour Protection Installation\",\n",
        "    \"Mooring System Installation\",\n",
        "    \"Turbine Installation\",\n",
        "    \"Soft\",\n",
        "    \"Project\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8b81a4ef-cd8d-4f94-acdc-47f291d83573",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_waves(project_floating):\n",
        "    start2 = perf_counter()\n",
        "    project_floating.run(full_wind_rose=False)\n",
        "    project_floating.wombat.env.cleanup_log_files()  # Delete logging data from the WOMBAT simulations\n",
        "    end2 = perf_counter()\n",
        "    \n",
        "    print(\"-\" * 29)  # separate our timing from the ORBIT and FLORIS run-time warnings\n",
        "    print(f\"Floating run time: {end2 - start2:,.2f} seconds\")\n",
        "\n",
        "    return project_floating\n",
        "\n",
        "def average_and_save(dfs, filename, index_cols=None):\n",
        "    df_concat = pd.concat(dfs)\n",
        "    if index_cols:\n",
        "        df_avg = df_concat.groupby(index_cols).mean()\n",
        "    else:\n",
        "        df_avg = df_concat.groupby(level=0).mean()\n",
        "    df_avg.to_csv(filename)\n",
        "    print(f\"Saved: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "31d673f1-5b7f-4058-a17a-ba5c271736f8",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Run 1 of 1\n",
            "ORBIT library intialized at 'C:\\Code\\WAVES\\library\\Standardized_Moorings'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: C:\\Code\\ORBIT\\ORBIT\\phases\\design\\array_system_design.py:1085\n",
            "Missing data in columns ['bury_speed']; all values will be calculated.UserWarning: C:\\Code\\ORBIT\\ORBIT\\phases\\design\\array_system_design.py:1085\n",
            "Missing data in columns ['bury_speed']; all values will be calculated.DeprecationWarning: C:\\Code\\ORBIT\\ORBIT\\manager.py:730\n",
            "landfall dictionary will be deprecated and moved into [export_system_design][landfall].DeprecationWarning: C:\\Code\\ORBIT\\ORBIT\\phases\\design\\_cables.py:417\n",
            "`trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Floating loading time: 1.37 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DeprecationWarning: C:\\Code\\ORBIT\\ORBIT\\phases\\install\\cable_install\\export.py:84\n",
            "landfall dictionary will be deprecated and moved into [export_system][landfall].DeprecationWarning: C:\\Code\\ORBIT\\ORBIT\\phases\\install\\quayside_assembly_tow\\moored.py:94\n",
            "support_vessel will be deprecated and replaced with towing_vessels and ahts_vessel in the towing groups.\n",
            "DeprecationWarning: C:\\Code\\ORBIT\\ORBIT\\phases\\install\\quayside_assembly_tow\\moored.py:94\n",
            "['towing_vessl_groups]['station_keeping_vessels'] will be deprecated and replaced with ['towing_vessl_groups]['ahts_vessels'].\n",
            "SettingWithCopyWarning: C:\\Code\\WAVES\\waves\\project.py:768\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copyRuntimeWarning: C:\\Users\\shousner\\AppData\\Roaming\\Python\\Python311\\site-packages\\floris\\core\\wake_deflection\\gauss.py:328\n",
            "invalid value encountered in divideRuntimeWarning: C:\\Users\\shousner\\AppData\\Roaming\\Python\\Python311\\site-packages\\floris\\core\\wake_deflection\\gauss.py:498\n",
            "invalid value encountered in divideRuntimeWarning: C:\\Users\\shousner\\AppData\\Roaming\\Python\\Python311\\site-packages\\floris\\core\\wake_deflection\\gauss.py:328\n",
            "divide by zero encountered in divide"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------\n",
            "Floating run time: 68.93 seconds\n"
          ]
        },
        {
          "ename": "PermissionError",
          "evalue": "[Errno 13] Permission denied: 'standmoor-results/deep_average_capex.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 180\u001b[39m\n\u001b[32m    177\u001b[39m     losses_dfs.append(report_df_losses) \n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# === Compute and save averages ===\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[43maverage_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcapex_dfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstandmoor-results/deep_average_capex.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mComponent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m average_and_save(opex_dfs, \u001b[33m\"\u001b[39m\u001b[33mstandmoor-results/deep_average_opex.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    182\u001b[39m average_and_save(charter_days_dfs, \u001b[33m\"\u001b[39m\u001b[33mstandmoor-results/deep_average_charter_days.csv\u001b[39m\u001b[33m\"\u001b[39m, index_cols=\u001b[33m\"\u001b[39m\u001b[33mvessel\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36maverage_and_save\u001b[39m\u001b[34m(dfs, filename, index_cols)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     17\u001b[39m     df_avg = df_concat.groupby(level=\u001b[32m0\u001b[39m).mean()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mdf_avg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\waves-env\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\waves-env\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\waves-env\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\waves-env\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\waves-env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'standmoor-results/deep_average_capex.csv'"
          ]
        }
      ],
      "source": [
        "NUM_RUNS = 1\n",
        "rng = np.random.default_rng(seed=834)\n",
        "\n",
        "# Containers for each metric\n",
        "capex_dfs = []\n",
        "opex_dfs = []\n",
        "charter_days_dfs = []\n",
        "mobilization_dfs = []\n",
        "delay_dfs = []\n",
        "failure_cost_dfs = []\n",
        "equipment_cost_dfs = []\n",
        "report_dfs = []\n",
        "losses_dfs = []\n",
        "\n",
        "library_path = Path(\"../library/Standardized_Moorings/\")\n",
        "config_floating = load_yaml(library_path / \"project/config\", \"base_floating_deep.yaml\")\n",
        "config_floating[\"floris_config\"] = load_yaml(library_path / \"project/config\", config_floating[\"floris_config\"])\n",
        "config_floating[\"floris_config\"][\"farm\"][\"turbine_library_path\"] = library_path / \"turbines\"\n",
        "config_floating.update({\"library_path\": library_path})\n",
        "\n",
        "config_wombat = load_yaml(library_path / \"project/config\", config_floating[\"wombat_config\"])\n",
        "\n",
        "for i in range(NUM_RUNS):\n",
        "    print(f\"\\nRun {i + 1} of {NUM_RUNS}\")\n",
        "\n",
        "    # Load the project\n",
        "    config = deepcopy(config_floating)\n",
        "    config_wombat[\"random_generator\"] = rng\n",
        "    config_floating[\"wombat_config\"] = config_wombat\n",
        "    \n",
        "    start = perf_counter()\n",
        "    project_floating = Project.from_dict(config_floating)\n",
        "    end = perf_counter()\n",
        "    print(f\"Floating loading time: {end - start:,.2f} seconds\")\n",
        "\n",
        "    # Run simulation\n",
        "    project_floating = run_waves(project_floating)\n",
        "\n",
        "    # Load key objects\n",
        "    ev = project_floating.wombat.metrics.events\n",
        "    years = project_floating.wombat.env.simulation_years\n",
        "    metrics = project_floating.wombat.metrics\n",
        "    materials = metrics.component_costs(\"project\", by_category=True, by_task=True, by_action=False)\n",
        "    avg_materials = materials[[\"materials_cost\"]] / years\n",
        "\n",
        "    # 0. CapEx Breakdown\n",
        "    df_capex_floating = pd.DataFrame(\n",
        "        project_floating.orbit.capex_detailed_soft_capex_breakdown.items(),\n",
        "        columns=[\"Component\", \"CapEx ($) - Floating\"]\n",
        "    )\n",
        "    df_capex_floating[\"CapEx ($/kW) - Floating\"] = (\n",
        "        df_capex_floating[\"CapEx ($) - Floating\"] / project_floating.capacity(\"kw\")\n",
        "    )\n",
        "\n",
        "    # Extract the onshore substation cost\n",
        "    onshore_substation_cost = (\n",
        "        project_floating.orbit.phases[\"ElectricalDesign\"]\n",
        "        .detailed_output[\"export_system\"][\"onshore_substation_costs\"]\n",
        "    )\n",
        "    onshore_substation_cost_per_kw = onshore_substation_cost / project_floating.capacity(\"kw\")\n",
        "\n",
        "    # Append onshore substation as a row\n",
        "    df_capex_floating.loc[len(df_capex_floating)] = [\n",
        "        \"Onshore Substation\",\n",
        "        onshore_substation_cost,\n",
        "        onshore_substation_cost_per_kw\n",
        "    ]\n",
        "\n",
        "    # Set index for consistent merging\n",
        "    df_capex_floating.set_index(\"Component\", inplace=True)\n",
        "    capex_dfs.append(df_capex_floating)\n",
        "    \n",
        "    # 1. Annual OpEx\n",
        "    opex_df = metrics.opex(frequency='annual', by_category=True)\n",
        "    opex_dfs.append(opex_df)\n",
        "\n",
        "    # 2. Average Charter Days\n",
        "    average_charter_days = []\n",
        "    for name, vessel in project_floating.wombat.service_equipment.items():\n",
        "        if vessel.settings.onsite or \"TOW\" in [el.value for el in vessel.settings.capability]:\n",
        "            continue\n",
        "        mobilizations = ev.loc[\n",
        "            (ev.action.eq(\"mobilization\") & ev.reason.str.contains(\"arrived on site\"))\n",
        "            & ev.agent.eq(name),\n",
        "            [\"agent\", \"env_time\"]\n",
        "        ]\n",
        "        leaving = ev.loc[\n",
        "            ev.action.eq(\"leaving site\")\n",
        "            & ev.agent.eq(name),\n",
        "            [\"agent\", \"env_time\"]\n",
        "        ]\n",
        "        if mobilizations.shape[0] - leaving.shape[0] == 1:\n",
        "            mobilizations = mobilizations.iloc[:-1]\n",
        "        charter_days = (leaving.env_time.values - mobilizations.env_time.values) / 24\n",
        "        average_charter_days.append([name, charter_days.mean()])\n",
        "    charter_days_df = pd.DataFrame(average_charter_days, columns=[\"vessel\", \"average charter days\"]).set_index(\"vessel\")\n",
        "    charter_days_dfs.append(charter_days_df)\n",
        "\n",
        "    # 3. Mobilization Summary\n",
        "    mobilization_summary = (\n",
        "        ev.loc[ev.action.eq(\"mobilization\") & ev.duration.gt(0), [\"agent\", \"duration\"]]\n",
        "        .groupby(\"agent\")\n",
        "        .count()\n",
        "        .rename(columns={\"duration\": \"mobilizations\"})\n",
        "        .join(\n",
        "            ev.loc[ev.action.eq(\"mobilization\"), [\"agent\", \"duration\", \"equipment_cost\"]]\n",
        "            .groupby(\"agent\")\n",
        "            .sum()\n",
        "        )\n",
        "    )\n",
        "    mobilization_summary.duration /= 24\n",
        "    mobilization_dfs.append(mobilization_summary)\n",
        "\n",
        "    # 4. Delay Summary\n",
        "    delay_summary = (\n",
        "        ev.loc[\n",
        "            ev.agent.isin(project_floating.wombat.service_equipment)\n",
        "            & ev.duration.gt(0)\n",
        "            & ev.action.eq(\"delay\"),\n",
        "            [\"agent\", \"additional\", \"duration\"]\n",
        "        ]\n",
        "        .replace({\n",
        "            \"no work requests submitted by start of shift\": \"no requests\",\n",
        "            \"no work requests, waiting until the next shift\": \"no requests\",\n",
        "            \"weather unsuitable to transfer crew\": \"weather delay\",\n",
        "            \"work shift has ended; waiting for next shift to start\": \"end of shift\",\n",
        "            \"insufficient time to complete travel before end of the shift\": \"end of shift\",\n",
        "            \"will return next year\": \"end of charter\",\n",
        "        })\n",
        "        .groupby([\"agent\", \"additional\"])\n",
        "        .sum()\n",
        "        .reset_index(drop=False)\n",
        "        .set_index([\"agent\", \"additional\"])\n",
        "        / 24\n",
        "    )\n",
        "    delay_dfs.append(delay_summary)\n",
        "\n",
        "    # 5. Failure Costs\n",
        "    timing = metrics.process_times()[[\"N\"]].rename(columns={\"N\": \"annual_occurrences\"}) / years\n",
        "    average_failures_costs = (\n",
        "        avg_materials\n",
        "        .rename(columns={\"materials_cost\": \"annual_materials_cost\"})\n",
        "        .join(timing, how=\"outer\")\n",
        "        .fillna(0.0)\n",
        "    )\n",
        "    failure_cost_dfs.append(average_failures_costs)\n",
        "\n",
        "    # 6. Equipment Cost Summary\n",
        "    equipment_cost_df = metrics.equipment_costs(frequency=\"annual\", by_equipment=True)\n",
        "    equipment_cost_dfs.append(equipment_cost_df)\n",
        "\n",
        "    # 7. Report DF\n",
        "    project_name_floating = \"Standardized Moorings Case - Floating\"\n",
        "    report_df_floating = project_floating.generate_report(metrics_configuration, project_name_floating).T\n",
        "    n_years_floating = project_floating.operations_years\n",
        "    additional_reporting = pd.DataFrame(\n",
        "        [\n",
        "            [\"FCR (%)\", project_floating.fixed_charge_rate],\n",
        "            [\"Offtake Price ($/MWh)\", project_floating.offtake_price],\n",
        "            [\n",
        "                \"Annual OpEx per kW ($/kW)\",\n",
        "                report_df_floating.loc[\"OpEx per kW ($/kW)\", project_name_floating] / n_years_floating\n",
        "            ],\n",
        "            [\"Potential AEP from WOMBAT (kWh)\", project_floating.wombat.metrics.potential.windfarm.values.sum()/n_years_floating],\n",
        "            [\"Production AEP from WOMBAT (kWh)\", project_floating.wombat.metrics.production.windfarm.values.sum()/n_years_floating],\n",
        "        ],\n",
        "        columns=[\"Project\"] + report_df_floating.columns.tolist(),\n",
        "    ).set_index(\"Project\")\n",
        "\n",
        "    report_df_floating = pd.concat((report_df_floating, additional_reporting), axis=0)\n",
        "    report_df_floating.index.name = \"Metrics\"\n",
        "    report_df_floating.loc[report_df_floating.index.str.contains(\"%\")] *= 100\n",
        "    report_dfs.append(report_df_floating)\n",
        "\n",
        "    #8. Losses report\n",
        "    report_df_losses = project_floating.loss_ratio(breakdown=True)\n",
        "    losses_dfs.append(report_df_losses) \n",
        "\n",
        "# === Compute and save averages ===\n",
        "average_and_save(capex_dfs, \"standmoor-results/deep_average_capex.csv\", index_cols=\"Component\")\n",
        "average_and_save(opex_dfs, \"standmoor-results/deep_average_opex.csv\")\n",
        "average_and_save(charter_days_dfs, \"standmoor-results/deep_average_charter_days.csv\", index_cols=\"vessel\")\n",
        "average_and_save(mobilization_dfs, \"standmoor-results/deep_average_mobilization_summary.csv\", index_cols=\"agent\")\n",
        "average_and_save(delay_dfs, \"standmoor-results/deep_average_delay_summary.csv\", index_cols=[\"agent\", \"additional\"])\n",
        "average_and_save(failure_cost_dfs, \"standmoor-results/deep_average_failures_costs.csv\", index_cols=[\"subassembly\", \"task\"])\n",
        "average_and_save(equipment_cost_dfs, \"standmoor-results/deep_average_equipment_costs.csv\")\n",
        "average_and_save(report_dfs, \"standmoor-results/deep_average_report_df.csv\", index_cols=\"Metrics\")\n",
        "average_and_save(losses_dfs, \"standmoor-results/deep_average_losses_report_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8268d451-8438-4fd2-9dd5-d9a5e36430b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.concat(failure_cost_dfs).reset_index().groupby([\"subassembly\", \"task\"]).sum() / years / NUM_RUNS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5557bb02-1c0e-49e7-a225-a8cc93637a4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "project_floating.plot_farm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f5a8a67-3cbc-444a-9647-ee8f325529ec",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "jupytext": {
      "text_representation": {
        "extension": ".md",
        "format_name": "myst"
      }
    },
    "kernelspec": {
      "display_name": "waves-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "source_map": [
      10,
      42,
      55,
      78,
      91,
      98,
      116,
      122,
      124,
      139,
      161,
      196,
      284,
      294,
      317,
      321
    ]
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
